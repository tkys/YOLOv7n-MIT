"""
YOLOv7n MIT Edition - Dockerç’°å¢ƒãƒ†ã‚¹ãƒˆ
Dockerç’°å¢ƒã§ã®å„ç¨®æ©Ÿèƒ½ã®å‹•ä½œç¢ºèª
"""

import json
import os
import time
from pathlib import Path
from typing import Dict, List

import requests
from inference.logger import get_logger

logger = get_logger("docker_test")

class DockerEnvironmentTest:
    """Dockerç’°å¢ƒãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒåˆæœŸåŒ–"""
        self.test_results = {}
        logger.info("Dockerç’°å¢ƒãƒ†ã‚¹ãƒˆåˆæœŸåŒ–")
    
    def test_basic_imports(self) -> Dict:
        """åŸºæœ¬çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        logger.info("åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_results = {"status": "success", "failed_imports": []}
        
        # å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        essential_imports = [
            ("numpy", "import numpy as np"),
            ("opencv", "import cv2"),
            ("onnxruntime", "import onnxruntime as ort"),
            ("fastapi", "from fastapi import FastAPI"),
            ("uvicorn", "import uvicorn"),
            ("matplotlib", "import matplotlib.pyplot as plt"),
            ("pillow", "from PIL import Image"),
            ("psutil", "import psutil"),
            ("tqdm", "from tqdm import tqdm"),
            ("jinja2", "from jinja2 import Template")
        ]
        
        for package_name, import_statement in essential_imports:
            try:
                exec(import_statement)
                logger.debug(f"âœ… {package_name} ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            except ImportError as e:
                logger.error(f"âŒ {package_name} ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
                test_results["failed_imports"].append({
                    "package": package_name,
                    "error": str(e)
                })
        
        if test_results["failed_imports"]:
            test_results["status"] = "failed"
        
        logger.info(f"åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆå®Œäº†: {test_results['status']}")
        return test_results
    
    def test_model_loading(self) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        logger.info("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ã‚µãƒ³ãƒ—ãƒ«ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹æ¢ç´¢
        model_paths = []
        model_dirs = ["models", "runs/train", "."]
        
        for model_dir in model_dirs:
            model_dir_path = Path(model_dir)
            if model_dir_path.exists():
                model_paths.extend(model_dir_path.glob("*.onnx"))
                model_paths.extend(model_dir_path.glob("**/*.onnx"))
        
        if not model_paths:
            return {
                "status": "skipped",
                "reason": "No ONNX models found"
            }
        
        test_model = model_paths[0]
        logger.info(f"ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«: {test_model}")
        
        try:
            import onnxruntime as ort
            
            # ONNX Runtime ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆãƒ†ã‚¹ãƒˆ
            providers = ['CPUExecutionProvider']
            session = ort.InferenceSession(str(test_model), providers=providers)
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—
            input_info = session.get_inputs()[0]
            output_info = session.get_outputs()[0]
            
            model_info = {
                "status": "success",
                "model_path": str(test_model),
                "input_name": input_info.name,
                "input_shape": input_info.shape,
                "output_name": output_info.name,
                "output_shape": output_info.shape,
                "providers": session.get_providers()
            }
            
            logger.info("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            return model_info
            
        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "status": "failed",
                "model_path": str(test_model),
                "error": str(e)
            }
    
    def test_inference_functionality(self) -> Dict:
        """æ¨è«–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        logger.info("æ¨è«–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from inference.single_image import SingleImageInference
            
            # ã‚µãƒ³ãƒ—ãƒ«ONNXãƒ¢ãƒ‡ãƒ«æ¢ç´¢
            model_paths = list(Path("models").glob("*.onnx")) + \
                         list(Path(".").glob("*.onnx"))
            
            if not model_paths:
                return {
                    "status": "skipped",
                    "reason": "No ONNX models found for inference test"
                }
            
            test_model = model_paths[0]
            
            # æ¨è«–å™¨åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
            inferencer = SingleImageInference(
                model_path=str(test_model),
                confidence_threshold=0.5
            )
            
            # ãƒ†ã‚¹ãƒˆç”»åƒä½œæˆï¼ˆãƒ€ãƒŸãƒ¼ç”»åƒï¼‰
            import numpy as np
            import cv2
            
            test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            test_image_path = "/tmp/test_image.jpg"
            cv2.imwrite(test_image_path, test_image)
            
            # æ¨è«–å®Ÿè¡Œ
            start_time = time.time()
            result = inferencer.predict(test_image_path)
            inference_time = time.time() - start_time
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(test_image_path)
            
            test_result = {
                "status": "success",
                "model_used": str(test_model),
                "inference_time": inference_time,
                "num_detections": result["num_detections"],
                "timing": result["timing"]
            }
            
            logger.info(f"æ¨è«–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆæˆåŠŸ: {inference_time:.3f}s")
            return test_result
            
        except Exception as e:
            logger.error(f"æ¨è«–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "status": "failed",
                "error": str(e)
            }
    
    def test_api_server(self, timeout: int = 30) -> Dict:
        """APIã‚µãƒ¼ãƒãƒ¼ãƒ†ã‚¹ãƒˆ"""
        logger.info("APIã‚µãƒ¼ãƒãƒ¼ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ãƒ†ã‚¹ãƒˆ
            from inference.api import app
            
            # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ç¢ºèª
            if app is None:
                return {
                    "status": "failed",
                    "error": "FastAPI app not initialized"
                }
            
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ©Ÿèƒ½ç¢ºèª
            # æ³¨æ„: å®Ÿéš›ã®HTTPã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã¯ã—ãªã„ï¼ˆç’°å¢ƒãƒ†ã‚¹ãƒˆã®ãŸã‚ï¼‰
            
            test_result = {
                "status": "success",
                "app_initialized": True,
                "endpoints_available": [
                    "/health",
                    "/predict/single", 
                    "/predict/batch",
                    "/"
                ]
            }
            
            logger.info("APIã‚µãƒ¼ãƒãƒ¼ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            return test_result
            
        except Exception as e:
            logger.error(f"APIã‚µãƒ¼ãƒãƒ¼ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "status": "failed",
                "error": str(e)
            }
    
    def test_logging_system(self) -> Dict:
        """ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        logger.info("ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from inference.logger import get_logger
            
            # æ–°ã—ã„ãƒ­ã‚¬ãƒ¼ä½œæˆ
            test_logger = get_logger("test_logger")
            
            # å„ãƒ¬ãƒ™ãƒ«ã®ãƒ­ã‚°å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
            test_logger.debug("ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ã‚¹ãƒˆ")
            test_logger.info("æƒ…å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ã‚¹ãƒˆ")
            test_logger.warning("è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ã‚¹ãƒˆ")
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            log_dir = Path("logs")
            if log_dir.exists():
                log_files = list(log_dir.glob("*.log"))
                test_result = {
                    "status": "success",
                    "log_dir_exists": True,
                    "log_files_count": len(log_files),
                    "log_files": [str(f) for f in log_files]
                }
            else:
                test_result = {
                    "status": "partial",
                    "log_dir_exists": False,
                    "note": "Log directory not created yet"
                }
            
            logger.info("ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")
            return test_result
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "status": "failed",
                "error": str(e)
            }
    
    def test_resource_monitoring(self) -> Dict:
        """ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ãƒ†ã‚¹ãƒˆ"""
        logger.info("ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            import psutil
            
            # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—
            cpu_count = psutil.cpu_count()
            memory_info = psutil.virtual_memory()
            cpu_percent = psutil.cpu_percent(interval=1)
            
            resource_info = {
                "status": "success",
                "cpu_count": cpu_count,
                "memory_total_gb": memory_info.total / (1024**3),
                "memory_available_gb": memory_info.available / (1024**3),
                "memory_usage_percent": memory_info.percent,
                "cpu_usage_percent": cpu_percent
            }
            
            logger.info("ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            return resource_info
            
        except Exception as e:
            logger.error(f"ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "status": "failed",
                "error": str(e)
            }
    
    def run_all_tests(self) -> Dict:
        """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("Dockerç’°å¢ƒåŒ…æ‹¬ãƒ†ã‚¹ãƒˆé–‹å§‹")
        start_time = time.time()
        
        # å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test_suite = {
            "basic_imports": self.test_basic_imports,
            "model_loading": self.test_model_loading,
            "inference_functionality": self.test_inference_functionality,
            "api_server": self.test_api_server,
            "logging_system": self.test_logging_system,
            "resource_monitoring": self.test_resource_monitoring
        }
        
        results = {
            "test_summary": {
                "start_time": start_time,
                "environment": "docker",
                "total_tests": len(test_suite)
            },
            "test_results": {}
        }
        
        passed_tests = 0
        failed_tests = 0
        skipped_tests = 0
        
        for test_name, test_function in test_suite.items():
            logger.info(f"å®Ÿè¡Œä¸­: {test_name}")
            
            try:
                test_result = test_function()
                results["test_results"][test_name] = test_result
                
                status = test_result.get("status", "unknown")
                if status == "success":
                    passed_tests += 1
                elif status == "failed":
                    failed_tests += 1
                else:
                    skipped_tests += 1
                    
            except Exception as e:
                logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ {test_name}: {e}")
                results["test_results"][test_name] = {
                    "status": "error",
                    "error": str(e)
                }
                failed_tests += 1
        
        # ãƒ†ã‚¹ãƒˆå®Œäº†æƒ…å ±
        total_time = time.time() - start_time
        results["test_summary"].update({
            "end_time": time.time(),
            "total_time": total_time,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "skipped_tests": skipped_tests,
            "success_rate": passed_tests / len(test_suite) * 100
        })
        
        logger.info(
            f"Dockerç’°å¢ƒãƒ†ã‚¹ãƒˆå®Œäº†: {passed_tests}/{len(test_suite)} æˆåŠŸ ({total_time:.2f}s)"
        )
        
        return results
    
    def print_test_summary(self, results: Dict):
        """ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ³ Dockerç’°å¢ƒãƒ†ã‚¹ãƒˆçµæœ")
        print("="*60)
        
        summary = results["test_summary"]
        print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆã‚µãƒãƒªãƒ¼:")
        print(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {summary['total_tests']}")
        print(f"  æˆåŠŸ: {summary['passed_tests']}")
        print(f"  å¤±æ•—: {summary['failed_tests']}")
        print(f"  ã‚¹ã‚­ãƒƒãƒ—: {summary['skipped_tests']}")
        print(f"  æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"  å®Ÿè¡Œæ™‚é–“: {summary['total_time']:.2f}ç§’")
        
        print(f"\nğŸ“‹ è©³ç´°çµæœ:")
        for test_name, test_result in results["test_results"].items():
            status = test_result.get("status", "unknown")
            status_emoji = {
                "success": "âœ…",
                "failed": "âŒ", 
                "skipped": "â­ï¸",
                "partial": "âš ï¸",
                "error": "ğŸ’¥"
            }.get(status, "â“")
            
            print(f"  {status_emoji} {test_name}: {status}")
            
            if status == "failed" and "error" in test_result:
                print(f"    ã‚¨ãƒ©ãƒ¼: {test_result['error']}")
        
        print("\n" + "="*60)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Dockerç’°å¢ƒãƒ†ã‚¹ãƒˆ")
    parser.add_argument("--output", help="çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°å‡ºåŠ›")
    
    args = parser.parse_args()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    docker_test = DockerEnvironmentTest()
    results = docker_test.run_all_tests()
    
    # çµæœè¡¨ç¤º
    docker_test.print_test_summary(results)
    
    # çµæœä¿å­˜
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nè©³ç´°çµæœä¿å­˜: {args.output}")
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰è¨­å®š
    success_rate = results["test_summary"]["success_rate"]
    if success_rate < 80:
        print("\nâš ï¸  è­¦å‘Š: ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ãŒ80%æœªæº€ã§ã™")
        exit(1)
    elif success_rate < 100:
        print("\nâš ï¸  æ³¨æ„: ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã¾ãŸã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
        exit(0)
    else:
        print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        exit(0)

if __name__ == "__main__":
    main()